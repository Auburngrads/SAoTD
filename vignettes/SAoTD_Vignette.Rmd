---
title: "SAoTD Vignette"
author: "Evan Munson"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{SAoTD Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEnconding{UTF-8}
---

# Sentiment Analysis of Twitter Data (SAoTD)

## Twitter Introduction

Recent years have witnessed the rapid growth of social media platforms in which users can publish their individual thoughts and opinions (e.g., Facebook, Twitter, Google+ and several blogs).  The rise in popularity of social media has changed the world wide web from a static repository to a dynamic forum for anyone to voice their opinion across the globe.  This new dimension of _User Generated Content_ opens up a new and dynamic source of insight to individuals, organizations and governments.

Social network sites or platforms, are defined as web-based services that allow individuals to:

* Construct a public or semi-public profile within a bounded system.
* Articulate a list of other users with whom they share a connection.
* View and traverse their list of connections and those made by others within the system.

The nature and nomenclature of these connections may vary from site to site.

This package, `SAoTD` is focused on utilizing Twitter data due to its widespread global acceptance.  Harvested data, analyzed for sentiment can provide powerful insight into a population.  This insight can assist organizations, by letting them better understand their target population.  This package will allow a useer to acquire data using the Public Twitter Application Programming Interface (API), to obtain tweets.

once users have a [Twitter](https://twitter.com/) account and a 

The `SAoTD` package is broken down into five different phases:

* Acquire
* Explore
* Topic Analysis
* Sentiment Calculation
* Visualization

## Packages

```{r warning=FALSE, message=FALSE}
library(SAoTD)
library(tidyverse)
library(tidytext)
library(kableExtra)
library(utils)
```

## Acquire

To explore the data manipulation functions of `SAoTD` we will use the built in dataset `SAoTD::raw_tweets`.

However is you want to acquire your own tweets, you will first have to:

1. Create a [twitter](https://twitter.com/) account or sign into existing account.

2. Use your twitter login, to sign into [Twitter Developers](https://dev.twitter.com/apps/)

3. Navigate to My Applications.

4. Fill out the new application form.
    + You will be asked to provide a website.  
    + You can input your twitter account website.  
    + For example:  https://twitter.com/yourusername

5. Create access token.
    + Record twitter access keys and tokens
    
With these steps complete you now have access to the twitter API.

To acquire your own dataset of tweets you can use the `SAoTD::Acquire` function and insert your consumer key, consumer secret key, access token and access secret key gained from the [Twitter Developers](https://dev.twitter.com/apps/) page.

```{r eval=FALSE}
consumer_key <- "XXXXXXXXXXXXXXXXXXXXXXXXX"
consumer_secret <- "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
access_token <- "XXXXXXXXXXXXXXXXXX-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
access_secret <- "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"

hashtags <- c("#job", "#Friday", "#fail", "#icecream", "#random", "#kitten", "#airline")

Acquire(consumer_key = consumer_key, 
        consumer_secret = consumer_secret,
        access_token = access_token, 
        access_secret = access_secret,
        HT = hashtags,
        num_tweets = 1000,
        file_name = "test_tweets.RData",
        distinct = TRUE)
         
load("test_tweets.RData")
```

## Explore

You can acquire your own data or use the dataset included with the package.  We will be using the included data `raw_tweets`.

```{r}
data("raw_tweets")
TD <- raw_tweets
```

The second tweet of the dataset is:  __`r TD$text[2]`__, and when it is cleaned and tidy'd it becomes:

```{r}
TD_Tidy <- SAoTD::Tidy(DataFrame = TD)

TD_Tidy$Token[11:20] %>% 
  knitr::kable("html")
```

The cleaning process removes:  “@”, “#” and "RT" symbols, Weblinks, Punctuation, Emojis, and Stop Words like (”the”, “of”, etc.).

We will now investigate Uni-Grams, Bi-Grams and Tri-Grams.

```{r message=FALSE}
SAoTD::Unigram(DataFrame = TD) %>% 
  dplyr::top_n(10) %>% 
  knitr::kable("html", caption = "Twitter data Uni-Grams")
```

```{r message=FALSE}
SAoTD::Bigram(DataFrame = TD) %>% 
  dplyr::top_n(10) %>% 
  knitr::kable("html", caption = "Twitter data Bi-Grams")
```

```{r message=FALSE}
SAoTD::Trigram(DataFrame = TD) %>% 
  dplyr::top_n(10) %>% 
  knitr::kable("html", caption = "Twitter data Tri-Grams")
```

Now that we have the Uni-Grams we can see that ice and cream are refereing to ice cream and may be good set of words to merge into a single term.  Additionally, pet and pets could also be merged to observe more uniquess in the data.

```{r message=FALSE, message=FALSE, error=FALSE}
TD_Merge <- Merge.Terms(DataFrame = TD, term = "ice cream", term_replacement = "icecream")
```

Now that the terms have been merged, the new N-Grams are re-computed.

```{r message=FALSE}
SAoTD::Unigram(DataFrame = TD_Merge) %>% 
  dplyr::top_n(10) %>% 
  knitr::kable("html", caption = "Twitter data Uni-Grams")
```

```{r message=FALSE}
SAoTD::Bigram(DataFrame = TD_Merge) %>% 
  dplyr::top_n(10) %>% 
  knitr::kable("html", caption = "Twitter data Bi-Grams")
```

```{r message=FALSE}
SAoTD::Trigram(DataFrame = TD_Merge) %>% 
  dplyr::top_n(10) %>% 
  knitr::kable("html", caption = "Twitter data Tri-Grams")
```

Now we can look at Bi-Gram Networks.

```{r fig.align='center', warning=FALSE}
TD_Bigrams <- SAoTD::Bigram(DataFrame = TD_Merge)

SAoTD::Bigram.Network(BiGramDataFrame = TD_Bigrams,
                      number = 100, 
                      layout = "fr", 
                      edge_color = "blue", 
                      node_color = "black", 
                      node_size = 3,
                      set_seed = 1234)
```

Additionally we can observe the Correlation Network.

```{r fig.align='center'}
TD_Corr <- SAoTD::Word.Corr(DataFrameTidy = TD_Tidy, number = 200, sort = TRUE)

SAoTD::Word.Corr.Plot(WordCorr = TD_Corr, 
                      Correlation = .1, 
                      layout = "fr", 
                      edge_color = "blue", 
                      node_color = "black", 
                      node_size = 1)
```

If we were interested in condcuting a topic analysis on the tweets we would then determine the number of latent topics within the tweet data.

```{r fig.align='center', warning=FALSE, message=FALSE, results="hide", cache=TRUE}
SAoTD::Number.Topics(DataFrame = TD, 
                     num_cores = 2L, 
                     min_clusters = 2, 
                     max_clusters = 12, 
                     skip = 1, 
                     set_seed = 1234)
```

The number of topics plot shows that between 5 and 7 latent topics reside within the dataset.  Remeber that the twitter data was acquired by selecting seven different hashtags `r hashtags <- c("#job", "#Friday", "#fail", "#icecream", "#random", "#kitten", "#airline")`.  We could easily see that in this case selecting 7 topics could be a correct number of topics.  However if we knew that the data contained 5 topics we could continue the analysis.  

```{r fig.align='center', warning=FALSE, message=FALSE, results="hide", cache=TRUE}
TD_Topics <- SAoTD::Tweet.Topics(DataFrame = TD, 
                                 clusters = 5, 
                                 method = "Gibbs", 
                                 set_seed = 1234, 
                                 num_terms = 10)
TD_Topics %>% 
  knitr::kable("html", caption = "Twitter data Topics")
```


